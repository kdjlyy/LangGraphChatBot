import os
import torch

torch.classes.__path__ = [os.path.join(torch.__path__[0], torch.classes.__file__)]

import uuid
import datetime
from dotenv import load_dotenv
from langchain.schema import Document
import streamlit as st
from streamlit_extras.bottom_container import bottom
from chains.models import load_vector_store
from graph.graph import create_graph, stream_graph_updates, GraphState
from utils.common import *

# è®¾ç½®ä¸Šä¼ æ–‡ä»¶çš„å­˜å‚¨è·¯å¾„
file_path = "upload_files/"
# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(verbose=True)

def upload_pdf(file):
    """ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶å¹¶è¿”å›æ–‡ä»¶è·¯å¾„"""
    with open(file_path + file.name, "wb") as f:
        f.write(file.getbuffer())
        return file_path + file.name

# è®¾ç½®é¡µé¢é…ç½®ä¿¡æ¯
st.set_page_config(
    page_title="AI èŠå¤©æœºå™¨äºº",
    page_icon="ğŸ¤–",
    layout="wide"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€å˜é‡ï¼Œåˆ›å»ºå›¾
if "graph" not in st.session_state:
    st.session_state.graph = create_graph()
# åˆå§‹åŒ–ä¼šè¯IDå’Œå‘é‡å­˜å‚¨
if "config" not in st.session_state:
    st.session_state.config = {"configurable": {"thread_id": uuid.uuid4().hex, "vectorstore": load_vector_store("BAAI/bge-m3")}}
# åˆå§‹åŒ–å¯¹è¯å†å²è®°å½•
if "history" not in st.session_state:
    st.session_state.history = []
# åˆå§‹åŒ–ä¸Šä¼ çŠ¶æ€ã€æ¨¡å‹åç§°å’Œå¯¹è¯ç±»å‹
if "settings" not in st.session_state:
    st.session_state.settings = {"uploaded": False, "model_name": "Qwen/QwQ-32B", "type": "chat"}

# æ˜¾ç¤ºåº”ç”¨æ ‡é¢˜
st.subheader("æˆ‘å¯ä»¥å¸®ä½ :blue[å†™ä»£ç ã€è¯»æ–‡ä»¶ã€è”ç½‘æœç´¢è§£å†³å„ç§é—®é¢˜]ï¼Œæ¬¢è¿å‘æˆ‘æé—®ï½ ğŸ˜¸", divider="gray")

# å®šä¹‰å¯é€‰çš„æ¨¡å‹
model_options = {"é€šä¹‰åƒé—®": "Qwen/QwQ-32B", "DeepSeek R1": "deepseek-ai/DeepSeek-R1"}
with st.sidebar:
    # ä¾§è¾¹æ è®¾ç½®éƒ¨åˆ†
    st.header("è®¾ç½®")
    # æ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†
    st.session_state.settings["model_name"] = model_options[st.selectbox("é€‰æ‹©æ¨¡å‹", model_options, index=list(model_options.values()).index(st.session_state.settings["model_name"]))]

    st.divider()

    # æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯
    st.caption(f"{datetime.datetime.now().strftime('%Y.%m')} - [LangGraphChatBot](https://github.com/kdjlyy/LangGraphChatBot)")
# å®šä¹‰å¯¹è¯ç±»å‹é€‰é¡¹
type_options = {"â­ï¸ ç¦»çº¿å¯¹è¯": "chat", "ğŸŒ è”ç½‘æœç´¢": "websearch", "âŒ¨ï¸ ä»£ç æ¨¡å¼": "code"}
question = None
with bottom():
    # åº•éƒ¨å®¹å™¨ï¼ŒåŒ…å«å·¥å…·é€‰æ‹©ã€æ–‡ä»¶ä¸Šä¼ å’Œè¾“å…¥æ¡†
    st.session_state.settings["type"] = type_options[st.radio("å·¥å…·é€‰æ‹©", type_options.keys(), horizontal=True, label_visibility="collapsed", index=list(type_options.values()).index(st.session_state.settings["type"]))]
    # æ–‡ä»¶ä¸Šä¼ ç»„ä»¶, pdfã€docã€xlsx æ ¼å¼çš„æ–‡ä»¶å¯èƒ½é€ æˆç³»ç»Ÿèµ„æºä¸è¶³
    uploaded_file = st.file_uploader("ä¸Šä¼ æ–‡ä»¶", type=["txt", "md"], accept_multiple_files=False, label_visibility="collapsed")
    # èŠå¤©è¾“å…¥æ¡†
    question = st.chat_input('è¾“å…¥æ‚¨è¦è¯¢é—®çš„å†…å®¹ï¼Œshift + enter æ¢è¡Œ')

# æ˜¾ç¤ºå†å²å¯¹è¯å†…å®¹
for message in st.session_state.history:
    with st.chat_message(message["role"]):
      st.markdown(message["content"])

# å¤„ç†ç”¨æˆ·æé—®
if question:
    # æ˜¾ç¤ºç”¨æˆ·é—®é¢˜
    with st.chat_message("user"):
        st.markdown(question)

    # å‡†å¤‡è¯·æ±‚çŠ¶æ€
    state = []
    message = [{"role": "system", "content": f"å½“å‰æ—¥æœŸæ˜¯ï¼š{get_current_time()}"}, {"role": "user", "content": question}]
    if st.session_state.settings["type"] == "code":
        # ä»£ç æ¨¡å¼ä½¿ç”¨ä¸“é—¨çš„ä»£ç æ¨¡å‹
        state = {"model_name": "Qwen/QwQ-32B", "messages": message, "type": "chat", "documents": []}
    else:
        # å…¶ä»–æ¨¡å¼ä½¿ç”¨é€‰æ‹©çš„æ¨¡å‹
        state = {"model_name": st.session_state.settings["model_name"], "messages": message, "type": st.session_state.settings["type"], "documents": []}

    # å¤„ç†æ–‡ä»¶ä¸Šä¼ 
    if uploaded_file:
        state["type"] = "file"
        if not st.session_state.settings["uploaded"]:
            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
            file_path = upload_pdf(uploaded_file)
            # æ·»åŠ æ–‡æ¡£åˆ°è¯·æ±‚
            state["documents"].append(Document(page_content=file_path))
            st.session_state.settings["uploaded"] = True

    # è·å–AIå›ç­”å¹¶ä»¥æµå¼æ–¹å¼æ˜¾ç¤º
    answer = st.chat_message("assistant").write_stream(stream_graph_updates(st.session_state.graph, state, st.session_state.config))

    # å°†å¯¹è¯ä¿å­˜åˆ°å†å²è®°å½•
    st.session_state.history.append({"role": "user", "content": question})
    st.session_state.history.append({"role": "assistant", "content": answer})
